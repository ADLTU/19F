{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Try Apache Beam - Python",
      "provenance": []
    },
    "kernelspec": {
      "name": "python2",
      "display_name": "Python 2"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# SetUP"
      ],
      "metadata": {
        "id": "REKxfTyUKQ-9"
      }
    },
    {
      "metadata": {
        "id": "GOOk81Jj_yUy"
      },
      "cell_type": "code",
      "source": [
        "## Install apache-beam.\n",
        "!pip install --quiet apache-beam\n",
        "\n",
        "## Creating work directory\n",
        "!mkdir -p data\n",
        "%cd data\n",
        "\n",
        "## Downloading data\n",
        "  # 2022 only data\n",
        "!wget http://prod.publicdata.landregistry.gov.uk.s3-website-eu-west-1.amazonaws.com/pp-2022.csv\n",
        "  # full data\n",
        "!wget http://prod.publicdata.landregistry.gov.uk.s3-website-eu-west-1.amazonaws.com/pp-complete.csv"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Development"
      ],
      "metadata": {
        "id": "XzdPqwXfKW5x"
      }
    },
    {
      "metadata": {
        "id": "oUqfqWyMuIfR"
      },
      "cell_type": "code",
      "source": [
        "import apache_beam as beam\n",
        "import json\n",
        "\n",
        "\n",
        "class GroupTransactions(beam.DoFn):\n",
        "    def process(self, transaction):\n",
        "        ## Constructing a unique property ID using relevant fields from the transaction\n",
        "        property_id = transaction['PAON'] + '_' + transaction['SAON'] + '_' + transaction['Postcode']\n",
        "        \n",
        "        ## Return the transaction with the property ID as the key\n",
        "        return [(property_id, transaction)]\n",
        "\n",
        "\n",
        "def run(csvPath, outputPath):\n",
        "\n",
        "    \"\"\" \n",
        "        :param str csvPath: the path to the input csv file\n",
        "        :param str outputPath: the path where you would like the resulted json file\n",
        "\n",
        "    \"\"\"\n",
        "    \n",
        "    with beam.Pipeline() as p:\n",
        "        ## Transform for reading the CSV file\n",
        "        read_file = beam.io.ReadFromText(csvPath)\n",
        "        ## Transform for reading the lines and removing the symbol (\")\n",
        "        parse_file = beam.Map(lambda row: row.replace('\"', '').split(','))\n",
        "        ## Transform for creating dictionaries\n",
        "        create_dictionary = beam.Map(lambda cols: {\n",
        "            'TransactionID': cols[0].replace('{', '').replace('}', ''), \n",
        "            'Price': cols[1],\n",
        "            'TransferDate': cols[2],\n",
        "            'Postcode': cols[3],\n",
        "            'PropertyType': cols[4],\n",
        "            'Old/New': cols[5],\n",
        "            'Duration': cols[6],\n",
        "            'PAON': cols[7],\n",
        "            'SAON': cols[8],\n",
        "            'Street': cols[9],\n",
        "            'Locality': cols[10],\n",
        "            'Town/City': cols[11],\n",
        "            'District': cols[12],\n",
        "            'County': cols[13],\n",
        "            'PPDCategory': cols[14]\n",
        "        })\n",
        "\n",
        "        ## Loading transactions data\n",
        "        transactions = p | read_file | parse_file | create_dictionary\n",
        "\n",
        "\n",
        "\n",
        "        ## Transform for creating a property ID\n",
        "        add_key = beam.ParDo(GroupTransactions())\n",
        "        ## Transform for grouping transactions by property ID\n",
        "        group_by_key = beam.GroupByKey()\n",
        "        ## Transform for creating json\n",
        "        json_format = beam.Map(lambda x:\n",
        "            json.dumps({'property_id': x[0], 'transactions': x[1]})\n",
        "        )\n",
        "\n",
        "        ## Creating output\n",
        "        properties = transactions | add_key | group_by_key | json_format\n",
        "\n",
        "        print(outputPath)\n",
        "\n",
        "        # Write the output to a file in newline delimited JSON format\n",
        "        \n",
        "        properties | 'Write Output' >> beam.io.WriteToText(outputPath, shard_name_template='')\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# TESTING\n"
      ],
      "metadata": {
        "id": "odbVQg9QKDKN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## unit tests\n",
        "\n",
        "  #Testing the function that creates property ids\n",
        "example1 = {'TransactionID': 'EC7AD09A-8B44-9200-E053-6C04A8C0E306', 'Price': '9999950', 'TransferDate': '2022-06-14 00:00', 'Postcode': 'W12 9BL', 'PropertyType': 'O', 'Old/New': 'N', 'Duration': 'F', 'PAON': '98', 'SAON': 'FLAT', 'Street': 'ASKEW ROAD', 'Locality': '', 'Town/City': 'LONDON', 'District': 'HAMMERSMITH AND FULHAM', 'County': 'GREATER LONDON', 'PPDCategory': 'B'}\n",
        "out1 = [('98_FLAT_W12 9BL', {'TransactionID': 'EC7AD09A-8B44-9200-E053-6C04A8C0E306', 'Price': '9999950', 'TransferDate': '2022-06-14 00:00', 'Postcode': 'W12 9BL', 'PropertyType': 'O', 'Old/New': 'N', 'Duration': 'F', 'PAON': '98', 'SAON': 'FLAT', 'Street': 'ASKEW ROAD', 'Locality': '', 'Town/City': 'LONDON', 'District': 'HAMMERSMITH AND FULHAM', 'County': 'GREATER LONDON', 'PPDCategory': 'B'})]\n",
        "\n",
        "result1 = GroupTransactions().process(example1)\n",
        "\n",
        "try:\n",
        "  assert out1 == result1\n",
        "  print(\"Passed unit test\")\n",
        "except AssertionError:\n",
        "  print(\"ERROR: Failed unit test\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cXM0_ykUgAIR",
        "outputId": "265ecc52-ae19-4ca4-aa39-f697553a0a5f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Passed unit test\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## Integration tests\n",
        "import filecmp\n",
        "\n",
        "run(csvPath='/content/data/IntegrationTest1.csv', outputPath='/content/data/IntegrationTest1.json')\n",
        "\n",
        "expectedResults = '/content/data/IntegrationTest1.json'\n",
        "actualResults   = '/content/data/IntegrationResult1.json'\n",
        "\n",
        "\n",
        "try:\n",
        "  assert filecmp.cmp(expectedResults, actualResults)\n",
        "  print(\"Passed Integration test\")\n",
        "except AssertionError:\n",
        "  print(\"ERROR: Failed Integration test\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        },
        "id": "w7RCm5P3Kss5",
        "outputId": "0e98c39f-447f-405e-b5f3-3db6fecc6ecd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:apache_beam.runners.interactive.interactive_environment:Dependencies required for Interactive Beam PCollection visualization are not available, please use: `pip install apache-beam[interactive]` to install necessary dependencies to enable all data visualization features.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "        if (typeof window.interactive_beam_jquery == 'undefined') {\n",
              "          var jqueryScript = document.createElement('script');\n",
              "          jqueryScript.src = 'https://code.jquery.com/jquery-3.4.1.slim.min.js';\n",
              "          jqueryScript.type = 'text/javascript';\n",
              "          jqueryScript.onload = function() {\n",
              "            var datatableScript = document.createElement('script');\n",
              "            datatableScript.src = 'https://cdn.datatables.net/1.10.20/js/jquery.dataTables.min.js';\n",
              "            datatableScript.type = 'text/javascript';\n",
              "            datatableScript.onload = function() {\n",
              "              window.interactive_beam_jquery = jQuery.noConflict(true);\n",
              "              window.interactive_beam_jquery(document).ready(function($){\n",
              "                \n",
              "              });\n",
              "            }\n",
              "            document.head.appendChild(datatableScript);\n",
              "          };\n",
              "          document.head.appendChild(jqueryScript);\n",
              "        } else {\n",
              "          window.interactive_beam_jquery(document).ready(function($){\n",
              "            \n",
              "          });\n",
              "        }"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/data/IntegrationTest1.json\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:apache_beam.io.filebasedsink:Deleting 1 existing files in target path matching: \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Passed Integration test\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## End-to-end tests\n",
        "  # 2022 data file\n",
        "\n",
        "run(csvPath='/content/data/pp-2022.csv', outputPath='/content/data/pp-2022.json')\n",
        "\n",
        "with open('/content/data/pp-2022.json') as f:\n",
        "    line = f.readline()\n",
        "    print(line)\n",
        "    line = f.readline()\n",
        "    print(line)\n",
        "    line = f.readline()\n",
        "    print(line)"
      ],
      "metadata": {
        "id": "w0WFquZFKx3t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## End-to-end tests\n",
        "  # full data file\n",
        "\n",
        "run(csvPath='/content/data/pp-complete.csv', outputPath='/content/data/pp-complete.json')\n",
        "\n",
        "with open('/content/data/pp-complete.json') as f:\n",
        "    line = f.readline()\n",
        "    print(line)\n",
        "    line = f.readline()\n",
        "    print(line)\n",
        "    line = f.readline()\n",
        "    print(line)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i8QWF5OXo5iz",
        "outputId": "b7e5eae4-4af9-4908-e60a-d7ee9f6e698a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/data/pp-complete.json\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Solution 2"
      ],
      "metadata": {
        "id": "OhrEvGXhn51_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def run2(csvPath, outputPath):\n",
        "\n",
        "    \"\"\" \n",
        "        :param str csvPath: the path to the input csv file\n",
        "        :param str outputPath: the path where you would like the resulted json file\n",
        "\n",
        "    \"\"\"\n",
        "\n",
        "    properties = {}\n",
        "\n",
        "    with open(csvPath) as data:\n",
        "        for d in data:\n",
        "              transaction = d.replace('\"', '').split(',')\n",
        "\n",
        "              transaction_info = {\"TransactionID\": transaction[0].replace('{', '').replace('}', ''), \n",
        "                    \"Price\": transaction[1], \n",
        "                    \"TransferDate\": transaction[2], \n",
        "                    \"Postcode\": transaction[3], \n",
        "                    \"PropertyType\": transaction[4], \n",
        "                    \"Old/New\": transaction[5], \n",
        "                    \"Duration\": transaction[6], \n",
        "                    \"PAON\": transaction[7], \n",
        "                    \"SAON\": transaction[8], \n",
        "                    \"Street\": transaction[9], \n",
        "                    \"Locality\": transaction[10], \n",
        "                    \"Town/City\": transaction[11], \n",
        "                    \"District\": transaction[12], \n",
        "                    \"County\": transaction[13], \n",
        "                    \"PPDCategory\": transaction[14]\n",
        "                    }\n",
        "\n",
        "              property_id = transaction_info['PAON'] + '_' + transaction_info['SAON'] + '_' + transaction_info['Postcode']\n",
        "\n",
        "              if property_id in properties:\n",
        "                  properties[property_id].append(transaction_info)\n",
        "              else:\n",
        "                  properties[property_id] = [transaction_info]\n",
        "              pass\n",
        "\n",
        "\n",
        "    with open(outputPath, 'w') as f:\n",
        "        for property_ in properties:\n",
        "            json.dump({'property_id': property_, 'transactions': properties[property_]}, f)\n",
        "            f.write('\\n')"
      ],
      "metadata": {
        "id": "AgiRrLMTh2O6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Integration tests\n",
        "import filecmp\n",
        "\n",
        "run2(csvPath='/content/data/IntegrationTest1.csv', outputPath='/content/data/IntegrationTest2.json')\n",
        "\n",
        "expectedResults = '/content/data/IntegrationTest2.json'\n",
        "actualResults   = '/content/data/IntegrationResult1.json'\n",
        "\n",
        "\n",
        "try:\n",
        "  assert filecmp.cmp(expectedResults, actualResults)\n",
        "  print(\"Passed Integration test\")\n",
        "except AssertionError:\n",
        "  print(\"ERROR: Failed Integration test\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "haEfu3T2nqQS",
        "outputId": "9529106a-49ef-4e40-ef54-c2d3391e8674"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Passed Integration test\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "C89d1KeuoPOI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Speed Test \n",
        "import time\n",
        "start_time = time.time()\n",
        "run(csvPath='/content/data/pp-2022.csv', outputPath='/content/data/pp-2022.json')\n",
        "print(\"--- %s seconds ---\" % (time.time() - start_time))\n",
        "\n",
        "start_time = time.time()\n",
        "run2(csvPath='/content/data/pp-2022.csv', outputPath='/content/data/pp-2022.json')\n",
        "print(\"--- %s seconds ---\" % (time.time() - start_time))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "da1z907ioPQ6",
        "outputId": "334cb547-8841-46c6-d54e-244c5a5fab22"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/data/pp-2022.json\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:apache_beam.io.filebasedsink:Deleting 1 existing files in target path matching: \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- 68.81572771072388 seconds ---\n",
            "--- 35.15790843963623 seconds ---\n"
          ]
        }
      ]
    }
  ]
}